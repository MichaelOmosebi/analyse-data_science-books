{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3ff4d84-b69f-44c5-8d44-73e83b897b12",
   "metadata": {},
   "source": [
    "# <font color=blue> EXPLORATORY DATA ANLAYSIS & SENTIMENT ANALYSIS </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a721289b-d55b-49b7-994a-9fe40d49db02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d308ee13-ec8e-4546-a0c2-8fabfe635465",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv('cleaned_books.csv')\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebee6a2-dac0-4288-a227-1b181cd7b3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "books.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc7587c-c125-4803-ab8f-0737fb58a72a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.0 Exporatory analyses on Data Science books ðŸ“š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f546d1-17c2-4e1e-884c-6590525f512b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 1.1 Highest & Lowest PricesðŸ¤‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea28184-8bb8-4dd5-8d46-2840fb4da35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "books.nlargest(1, ['book_cost($)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fd8090-665c-4ef9-935c-fc3095df29e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "books.nsmallest(1, ['book_cost($)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea190f0-06e5-4068-b8de-c5cbeba3e149",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check lowest cost for books that are not 0$\n",
    "\n",
    "books[books['book_cost($)']>0].nsmallest(1, ['book_cost($)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9939a6-5a69-4903-b8e5-39c165ee92a6",
   "metadata": {},
   "source": [
    "> Good to see that the book with the lowest cost from the dataset has a very good rating!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04f1989-7f3e-4477-924a-96a5750bff1e",
   "metadata": {},
   "source": [
    "### 1.2 ðŸ’° Price vs. reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a89bec-2dda-439f-bdf1-5a43f6508741",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(books, x=\"book_cost($)\", y=\"rating\",size=\"rating_count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d76109-82b7-4e92-aa7c-85296c79f46a",
   "metadata": {},
   "source": [
    "> Book rating is not related to price: Some costly books have poor rating and some highly rated books are relatively cheap too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c52800c-1de1-4d5c-9ebd-9206e0f5f0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select books based on title containing \"Python\"\n",
    "python_books = books[books['title'].str.contains(\"Python\")]\n",
    "\n",
    "# Python books with most reviews and highest average rating\n",
    "best_python_books = python_books.nlargest(5, ['rating_count','rating'])\n",
    "best_python_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018359e5-62c4-4594-ba18-2ffd509021c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select books based on title containing \"Machine Learning\"\n",
    "ml_books = books[books['title'].str.contains(\"Machine Learning\")]\n",
    "\n",
    "# ML books with most reviews and highest average rating\n",
    "best_ml_books = ml_books.nlargest(5, ['rating_count','rating'])\n",
    "best_ml_books"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f30dffd-f84a-4524-868f-d89b253668e4",
   "metadata": {},
   "source": [
    "### 1.3 Distribution of Ratings Score per Book"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c8d1fb-624e-4621-8b28-e0cdd8d714b7",
   "metadata": {},
   "source": [
    "___\n",
    "Books without any rating/review have an overall default rating of zero.\n",
    "\n",
    "It is important to exclude these books whwn attempting to do an overall rating preview of all the books so as not to deflect the results since there are more books without ratings than books with ratings.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f537a4-e866-4b36-b0f1-22a7b0d7ff4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out books/rows with rating = 0\n",
    "df_rating = books[books['rating']>0.99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8697d4d-de28-4145-b3f3-2c08972eafa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create of plot of stars distribution\n",
    "ax = df_rating['rating'].sort_index().plot.hist(figsize=(10, 5), bins=5)\n",
    "\n",
    "ax.set_xlabel('Review Stars')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88996afc-88be-42e9-81e4-a0351d4f9d83",
   "metadata": {},
   "source": [
    "* Most of the rated books were rated 4-out-of-5 ðŸŒŸ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5868a8-1aeb-4785-86ac-e3fa065466ce",
   "metadata": {},
   "source": [
    "### 1.4 Most Popular Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988d5a7c-07c1-47f1-868d-efd6b70233b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a list of words from genres of each book/row \n",
    "genres = books['genre(s)'].dropna()\n",
    "genres = [g for g in genres if 'Genres' in g]#\n",
    "genres = [g.replace('Genres, ','') for g in genres]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f675ef-1935-430f-8b7a-e0976c7c9b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate wordcloud image\n",
    "unique_string=(\" \").join(genres)\n",
    "wordcloud = WordCloud(max_font_size=60, max_words=30, background_color=\"black\").generate(unique_string)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "#plt.savefig(\"your_file_name\"+\".png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f505c3-e88a-47bc-bb8e-f58fec167e1d",
   "metadata": {},
   "source": [
    "### 1.5 ðŸ§ Clustering Book by Titles "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c88460-9c09-4947-ae5d-c073ea3d313d",
   "metadata": {},
   "source": [
    "> ðŸ’¡ What are the main types of Data Science books?\n",
    "____\n",
    "\n",
    "A simple way of collecting similar book based on title, possible content.\n",
    "\n",
    "KMeans Clustering method will be used to achieve this clustering.\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37db5562-d1e4-4f24-aece-f3b8c160b387",
   "metadata": {},
   "source": [
    "#### 1.5.1 Applying the Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07aff74-396b-4f14-97d1-38ce886c6ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate Vectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "\n",
    "X = vectorizer.fit_transform(books[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e229cd-a72d-4e9f-995d-512835ba4143",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f62b87-d977-4b50-b225-890355927430",
   "metadata": {},
   "source": [
    "#### 1.5.2 Finding the Best Number of Clusters 'K'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae23fd7-2e68-4081-a501-d00f562ce231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Kmeans clustering model\n",
    "km = KMeans(n_clusters=k, max_iter=600, n_init=10)\n",
    "\n",
    "#iterate through a range up to 10 to find K\n",
    "sum_of_squared_distances = []\n",
    "\n",
    "K = range(2,10)\n",
    "for k in K:\n",
    "   km.fit(X)\n",
    "   sum_of_squared_distances.append(km.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf3e5e7-da47-434a-a861-e5948f592aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(K, sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Sum of squared distances')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885b07d4-b047-4ece-83cf-483644381272",
   "metadata": {},
   "source": [
    "> Visually we can see that the optimal number of clusters should be around 3 or 4. But visualizing/visualization of the data alone cannot always give the right answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3d0a6f-b04e-485b-9f65-2c7c1836f612",
   "metadata": {},
   "source": [
    "#### 1.5.3 Finding the Best Number of Clusters (Silhoutte Coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b7d90c-fdac-4af1-b914-e9ca6c09d50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_avg = []\n",
    "for k in K:\n",
    " \n",
    "     # initialise kmeans\n",
    "    kmeans = KMeans(n_clusters=k, max_iter=600, n_init=10)\n",
    "    kmeans.fit(X)\n",
    "    cluster_labels = kmeans.labels_\n",
    "\n",
    "     # silhouette score\n",
    "    silhouette_avg.append(silhouette_score(X, cluster_labels))\n",
    "\n",
    "    \n",
    "plt.plot(K, silhouette_avg)\n",
    "plt.xlabel('Values of K') \n",
    "plt.ylabel('Silhouette score') \n",
    "plt.title('Silhouette analysis For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506fb222-b07c-4169-aece-510d62fe9ccf",
   "metadata": {},
   "source": [
    "> The silhoutte coefficient continues to rise in a typical sinusoidal movement, yet very low. This indicates a high possibility of poor mismatching between clusters.\n",
    "\n",
    "> Low matching accuracy, w.r.t. our data here, infers the closeness in word choices used in titles of the varous genres.\n",
    "\n",
    "> For this project, a classification of 4 should work!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6c2333-6b5a-4f03-815c-d425ffbabe7d",
   "metadata": {},
   "source": [
    "#### 1.5.4 Create the Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a24d15-4cfd-484d-938b-f214b1629a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get clusters\n",
    "true_k = 4\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=600, n_init=10)\n",
    "model.fit(X)\n",
    "\n",
    "# Get prediction/ labels\n",
    "labels = model.labels_\n",
    "book_cl = pd.DataFrame(list(zip(books[\"title\"],labels)),columns=['title','cluster'])\n",
    "print(book_cl.sort_values(by=['cluster']))\n",
    "\n",
    "\n",
    "###introduce silhoutte score-----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2a9550-3d01-41ad-8572-177ce80e9ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = model.labels_\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1e47af-b574-4057-bc07-456339b1f48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create wordclouds for clusters\n",
    "for k in range(true_k):\n",
    "   text = book_cl[book_cl.cluster == k]['title'].str.cat(sep=' ')\n",
    "   wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(text)\n",
    "\n",
    "   # Create subplot\n",
    "   plt.subplot(2, 3, k+1).set_title(\"Cluster \" + str(k)) \n",
    "   plt.plot()\n",
    "   plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "   plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e845b55-652f-4544-8ab9-34a50e944a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on unseen data\n",
    "test = vectorizer.transform(['How to Become a Top Programmer'])\n",
    "model.predict(test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a6d37c-1f77-4952-a94f-7de05bff2c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cluster_num = '2'\n",
    "\n",
    "# Books in clusters\n",
    "book_cl[book_cl.cluster == int(cluster_num)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2272737d-ef2a-4c11-9b8a-f6f5c331a504",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.0 Book Reviews Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e8654b-4f92-4be4-b9dd-2e1829866670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Summarizing book reviews\n",
    "# from summarizer import Summarizer\n",
    "\n",
    "# bert_model = Summarizer()\n",
    "# bert_summary = ''.join(bert_model(books.foreward[2], ratio = 0.2))\n",
    "# print(bert_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c020f4f6-ec87-4559-8912-e17ea9a8022a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###!pip install sacremoses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baa5130-a03f-43ad-8c2f-c9afbce9d242",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3.0 Sentiment Analysis of Reviews\n",
    "\n",
    "In this section we will be doing some sentiment analysis in python using three different techniques:\n",
    "1. VADER (Valence Aware Dictionary and sEntiment Reasoner) - Bag of words approach\n",
    "2. Roberta Pretrained Model from _HuggingFace_ ðŸ¤—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cc3daf-b935-47e4-990c-89336c09ae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the book reviews data\n",
    "reviews = pd.read_csv('book_reviews.csv')\n",
    "reviews = reviews.rename(columns={'Unnamed: 0':'Id', 'rating':'stars'})\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9885471-e1a1-4b39-8886-0848bd9502a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ac9b8c-49f9-4b8a-8edb-4081de14968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.stars.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933c2728-12ef-4b0d-9de2-1c2834452827",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews[reviews['stars'].str.contains('el=\"Review ')==False]\n",
    "reviews.stars.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb89ae7-16b2-4b36-9d85-bea0ea3be707",
   "metadata": {},
   "source": [
    "### 3.1 Quick EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b80a96-0024-48ed-8de2-b8aff5d12766",
   "metadata": {},
   "source": [
    "___\n",
    "A quick clean of the rating column is required!\n",
    "\n",
    "To process, the rating column should contain single digits for number of stars given by each book reviewer. Column dtype also formatted.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f68b07-41bd-4629-b323-5b28ebd0351f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace the column by retaining only the score component of the review rating\n",
    "reviews['stars'] = [s[1] for s in reviews.stars]\n",
    "\n",
    "#change column type\n",
    "reviews['stars'] = reviews['stars'].astype('int')\n",
    "\n",
    "#nltk analyzer will not be able to process NaNs as texts, hence will throw an error\n",
    "reviews.dropna(inplace=True)\n",
    "\n",
    "#review cleaned data info\n",
    "reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab61b23-e893-4d2f-96d5-2c77d59f535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = reviews['stars'].value_counts().sort_index() \\\n",
    "    .plot(kind='bar',\n",
    "          title='Count of Reviews by Stars',\n",
    "          figsize=(10, 5))\n",
    "ax.set_xlabel('Review Stars')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93513208-fa01-4d83-8f43-0c6a001e7e6c",
   "metadata": {},
   "source": [
    "### 3.2 Natural Language Toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a437b4f0-0819-4eb6-84a3-92747df2030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a sample review\n",
    "example = reviews['review'][266]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc8f6d6-4129-4e74-b08d-fa167f66e793",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize the sample review\n",
    "tokens = nltk.word_tokenize(example)\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3796288-84e1-49a8-8734-23e17f44c2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get token tags\n",
    "tagged = nltk.pos_tag(tokens)\n",
    "tagged[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b952e745-6708-48fb-a82e-95a80f0e48c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = nltk.chunk.ne_chunk(tagged)\n",
    "entities.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f744765a-c0f5-4506-8acf-9a9f336f0563",
   "metadata": {},
   "source": [
    "#### 3.2.1 VADER Seniment Scoring\n",
    "\n",
    "We will use NLTK's `SentimentIntensityAnalyzer` to get the neg/neu/pos scores of the text.\n",
    "\n",
    "- This uses a \"bag of words\" approach:\n",
    "    1. Stop words are removed\n",
    "    2. each word is scored and combined to a total score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf12a17-8749-48b6-87e4-e7262a3d889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the VADER sentiment analyzer model\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c46c22-1f63-4e78-92f7-fb3d10eeeffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the polarity score for the sample\n",
    "sia.polarity_scores(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc839040-503a-4464-8914-c2df56b764e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the polarity score on the entire dataset\n",
    "res = {}\n",
    "for i, row in tqdm(reviews.iterrows(), total=len(reviews)):\n",
    "    text = row['review']\n",
    "    myid = row['Id']\n",
    "    res[myid] = sia.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f789ee7-1896-45d5-bbf8-41585a8d8ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vaders = pd.DataFrame(res).T\n",
    "vaders = vaders.reset_index().rename(columns={'index': 'Id'})\n",
    "vaders = vaders.merge(reviews, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b08a214-8f74-4b0c-bffd-c0ff9dbb89a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have sentiment score and metadata\n",
    "vaders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378b8f3c-4e4b-49ab-b8ad-84260f69882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "ax = sns.barplot(data=vaders, x='stars', y='compound')\n",
    "ax.set_title('Compund Score by Amazon Star Review')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a1a6e0-af38-4c47-9d4c-b4a2bc111a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(12, 3))\n",
    "sns.barplot(data=vaders, x='stars', y='pos', ax=axs[0])\n",
    "sns.barplot(data=vaders, x='stars', y='neu', ax=axs[1])\n",
    "sns.barplot(data=vaders, x='stars', y='neg', ax=axs[2])\n",
    "axs[0].set_title('Positive')\n",
    "axs[1].set_title('Neutral')\n",
    "axs[2].set_title('Negative')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d88f44-7e46-464d-883d-2890340f49b0",
   "metadata": {},
   "source": [
    "#### 3.2.2 Roberta Pretrained Model\n",
    "\n",
    "- Use a model trained on a large corpus of data.\n",
    "- Transformer model accounts for the words but also the context related to other words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eeccc4-5949-4f68-8c8d-16acf726125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INstantiate the transformer model\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8e1123-ea0d-4a22-9e20-bbb6b07d5725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reprint VADER results on example for context\n",
    "print(example)\n",
    "sia.polarity_scores(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e03dae-a300-4465-9027-097f13f64474",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = tokenizer(example, return_tensors='pt')\n",
    "output = model(**encoded_text)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8629a0f9-6b88-4957-a169-8b3f28d8f105",
   "metadata": {},
   "outputs": [],
   "source": [
    "#detach the results from the output\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aa7816-2a81-4384-b3a0-16dee805d424",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the numpy result using 'softmax' --- exponantial transformation\n",
    "scores = softmax(scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fa80d4-8e4d-4d68-85c4-d46d1fe4a9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_dict = {\n",
    "    'roberta_neg' : scores[0],\n",
    "    'roberta_neu' : scores[1],\n",
    "    'roberta_pos' : scores[2]\n",
    "}\n",
    "print(scores_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc74ac63-64dd-439e-9324-b80f4e85e188",
   "metadata": {},
   "source": [
    "> The Roberta model is able to capture nuances in expressions, and in this circumstance able to capture the negative sentiment in the sample expression, as against the VADER result that was unable to determine the negativity or positivity, hence giving more weight to 'neutral' position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ace9e5c-6624-445f-afcb-e832769ff752",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrap the flow in a function\n",
    "def polarity_scores_roberta(example):\n",
    "    encoded_text = tokenizer(example, return_tensors='pt')\n",
    "    output = model(**encoded_text)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    scores_dict = {\n",
    "        'roberta_neg' : scores[0],\n",
    "        'roberta_neu' : scores[1],\n",
    "        'roberta_pos' : scores[2]\n",
    "    }\n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2b09ad-944a-41b0-ba8a-dee89533603f",
   "metadata": {},
   "source": [
    "#### 3.2.3 Combine and Compare Both Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728d2784-3434-4296-9ee9-f5b4efe607fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-run the two models on the corpus to extract results\n",
    "res = {}\n",
    "for i, row in tqdm(reviews.iterrows(), total=len(reviews)):\n",
    "    try: #roberta model can only handle text of certain lenght of texts before it throws 'runtime' error\n",
    "        text = row['review']\n",
    "        myid = row['Id']\n",
    "        vader_result = sia.polarity_scores(text)\n",
    "        vader_result_rename = {}\n",
    "        for key, value in vader_result.items():\n",
    "            vader_result_rename[f\"vader_{key}\"] = value\n",
    "        roberta_result = polarity_scores_roberta(text)\n",
    "        both = {**vader_result_rename, **roberta_result}\n",
    "        res[myid] = both\n",
    "    except RuntimeError:\n",
    "        print(f'Broke for id {myid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1205d62-0925-439c-8678-6db3efad03c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine both results with the main dataframe\n",
    "results_df = pd.DataFrame(res).T\n",
    "results_df = results_df.reset_index().rename(columns={'index': 'Id'})\n",
    "results_df = results_df.merge(reviews, how='left')\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a22b92-bcfa-4737-9a84-54ec96fccd6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3.2.3.1 Compare Scores between models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f97f03f-a47c-4b0d-9ab2-3f94cbc696ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch column names\n",
    "results_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf69aeee-7714-4b17-b4d5-a1558cced84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using a PairPlot chat to compare\n",
    "sns.pairplot(data=results_df,\n",
    "             vars=['vader_neg', 'vader_neu', 'vader_pos',\n",
    "                  'roberta_neg', 'roberta_neu', 'roberta_pos'],\n",
    "            hue='stars',\n",
    "            palette='tab10')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294fd19a-e237-4239-87dd-072b8103c686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "527ee20e-b970-4564-846a-3b8f32685140",
   "metadata": {},
   "source": [
    "### 3.3 Review Differences in Perfromane of Both Models on Actual Ratings\n",
    "\n",
    "Lets look at some examples where the model scoring and review score differ the most."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26215264-c8ed-4f5c-a6d1-813b11b2c8f3",
   "metadata": {},
   "source": [
    "#### 3.3.1 Positive 1-Star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932bb2df-8182-47de-afcd-df3d41215a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.query('stars == 1') \\\n",
    "    .sort_values('roberta_pos', ascending=False)['review'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de8cc84-7bea-406c-9d82-c4c6b9670fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.query('stars == 1') \\\n",
    "    .sort_values('vader_pos', ascending=False)['review'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8edfdc7-b96c-40a8-b5b9-3f492257e8f0",
   "metadata": {},
   "source": [
    " #### 3.3.2 Negative 5-Star Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ee94a8-9d21-4dc7-b9a4-72ecc1ae1e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.query('stars == 5') \\\n",
    "    .sort_values('roberta_neg', ascending=False)['review'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719c8c05-a970-44f2-8e62-f489b03a1ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.query('stars == 5') \\\n",
    "    .sort_values('vader_neg', ascending=False)['review'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153f7ee1-62a0-4b5e-9f84-8cbb3e09f338",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4.0 Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f578657-a967-49cf-9ac5-2724d9485945",
   "metadata": {},
   "source": [
    "1. The ```VADER``` model is powerful and useful in quickly drawing sentiments from straight expressions.\n",
    "2. The ```Roberta``` model, beyond the capabilities of the _VADER_ model is able to discern nuances such as when sarcasm is meant, and evaluate such expression appropriately by considering the context around words.\n",
    "3. Human expression through language is diverse and as can be seen in the last section, there may be instances where model results will vary from true sentiments. Sometimes, the error may come from human input or the use of wrong words in the expression of thought."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6744273d-94c5-435b-8594-26e9b29f90ca",
   "metadata": {},
   "source": [
    "## 5.0 References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e21d66d-b54e-43c6-af50-7c850a28c96e",
   "metadata": {},
   "source": [
    "* [Python Sentiment Analysis Project with NLTK - Rob Mulla](https://www.youtube.com/watch?v=QpzMWQvxXWk&t=1s)\n",
    "* [I Analyzed 1000 Data Science Books on Amazon: Here's What I Found ðŸ¤“ - Thu Vu](https://www.youtube.com/watch?v=N0o-Bjiwt0M)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
